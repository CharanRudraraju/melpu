{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rnautiyal2\\Anaconda3\\envs\\charanfyp\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "from MeLU import MeLU\n",
    "from options import config\n",
    "from model_training import training\n",
    "from data_generation import generate\n",
    "from evidence_candidate import selection\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_path= \"./ml\"\n",
    "if not os.path.exists(\"{}/\".format(master_path)):\n",
    "    os.mkdir(\"{}/\".format(master_path))\n",
    "    # preparing dataset. It needs about 22GB of your hard disk space.\n",
    "    generate(master_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [20, 40, 50, 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 601/601 [00:02<00:00, 282.41it/s]\n",
      "100%|██████████| 20/20 [01:34<00:00,  4.74s/it]\n",
      "100%|██████████| 601/601 [00:01<00:00, 319.47it/s]\n",
      "100%|██████████| 40/40 [03:08<00:00,  4.72s/it]\n",
      "100%|██████████| 601/601 [00:01<00:00, 315.32it/s]\n",
      "100%|██████████| 50/50 [03:55<00:00,  4.71s/it]\n",
      "100%|██████████| 601/601 [00:01<00:00, 327.16it/s]\n",
      "100%|██████████| 60/60 [04:44<00:00,  4.74s/it]\n"
     ]
    }
   ],
   "source": [
    "for epoch in epochs:\n",
    "    # training model.\n",
    "    melu = MeLU(config)\n",
    "    state = \"user_cold_state\"\n",
    "    model_filename = \"{}/models_{}_{}.pkl\".format(master_path,state,epoch)\n",
    "    if not os.path.exists(model_filename):\n",
    "        training_set_size = int(len(os.listdir(\"{}/{}\".format(master_path,state))) / 4)\n",
    "        supp_xs_s = []\n",
    "        supp_ys_s = []\n",
    "        query_xs_s = []\n",
    "        query_ys_s = []\n",
    "        for idx in tqdm(range(training_set_size)):\n",
    "            supp_xs_s.append(pickle.load(open(\"{}/{}/supp_x_{}.pkl\".format(master_path,state, idx), \"rb\")))\n",
    "            supp_ys_s.append(pickle.load(open(\"{}/{}/supp_y_{}.pkl\".format(master_path, state, idx), \"rb\")))\n",
    "            query_xs_s.append(pickle.load(open(\"{}/{}/query_x_{}.pkl\".format(master_path, state, idx), \"rb\")))\n",
    "            query_ys_s.append(pickle.load(open(\"{}/{}/query_y_{}.pkl\".format(master_path, state, idx), \"rb\")))\n",
    "        total_dataset = list(zip(supp_xs_s, supp_ys_s, query_xs_s, query_ys_s))\n",
    "        del(supp_xs_s, supp_ys_s, query_xs_s, query_ys_s)\n",
    "        history = training(melu, total_dataset, batch_size=config['batch_size'], num_epoch=epoch, model_save=True, model_filename=model_filename)\n",
    "        training_losses.append(history[-1])\n",
    "    else:\n",
    "        testing_set_size = int(len(os.listdir(\"{}/{}\".format('testing',state))) / 4)\n",
    "        supp_xs_s_testing = []\n",
    "        supp_ys_s_testing = []\n",
    "        query_xs_s_testing = []\n",
    "        query_ys_s_testing = []\n",
    "        for idx in tqdm(range(testing_set_size)):\n",
    "            supp_xs_s_testing.append(pickle.load(open(\"{}/{}/supp_x_{}.pkl\".format('testing',state, idx), \"rb\")))\n",
    "            supp_ys_s_testing.append(pickle.load(open(\"{}/{}/supp_y_{}.pkl\".format('testing', state, idx), \"rb\")))\n",
    "            query_xs_s_testing.append(pickle.load(open(\"{}/{}/query_x_{}.pkl\".format('testing', state, idx), \"rb\")))\n",
    "            query_ys_s_testing.append(pickle.load(open(\"{}/{}/query_y_{}.pkl\".format('testing', state, idx), \"rb\")))\n",
    "        \n",
    "        trained_state_dict = torch.load(model_filename)\n",
    "        melu.load_state_dict(trained_state_dict)\n",
    "\n",
    "        final_loss = []\n",
    "        for i in range(len(supp_xs_s_testing)):\n",
    "            prediction = melu.model(supp_xs_s_testing[i].cuda())\n",
    "            temp_loss = F.mse_loss(prediction, supp_ys_s_testing[i].cuda().view(-1, 1))\n",
    "            final_loss.append(temp_loss.item())\n",
    "\n",
    "        for j in range(len(query_xs_s_testing)):\n",
    "            prediction = melu.model(query_xs_s_testing[j].cuda())\n",
    "            temp_loss = F.mse_loss(prediction, query_ys_s_testing[j].cuda().view(-1, 1))\n",
    "            final_loss.append(temp_loss.item())\n",
    "        testing_losses.append(np.mean(final_loss))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9896575985728083,\n",
       " 0.8461494526347598,\n",
       " 0.8154991994032988,\n",
       " 0.7716594467291961]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:00<00:00, 247.27it/s]\n",
      "100%|██████████| 67/67 [00:00<00:00, 307.38it/s]\n",
      "100%|██████████| 67/67 [00:00<00:00, 341.84it/s]\n",
      "100%|██████████| 67/67 [00:00<00:00, 325.24it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in epochs:\n",
    "    model_filename = \"{}/models_{}_{}.pkl\".format(master_path,state,epoch)\n",
    "    testing_set_size = int(len(os.listdir(\"{}/{}\".format('testing',state))) / 4)\n",
    "    supp_xs_s_testing = []\n",
    "    supp_ys_s_testing = []\n",
    "    query_xs_s_testing = []\n",
    "    query_ys_s_testing = []\n",
    "    for idx in tqdm(range(testing_set_size)):\n",
    "        supp_xs_s_testing.append(pickle.load(open(\"{}/{}/supp_x_{}.pkl\".format('testing',state, idx), \"rb\")))\n",
    "        supp_ys_s_testing.append(pickle.load(open(\"{}/{}/supp_y_{}.pkl\".format('testing', state, idx), \"rb\")))\n",
    "        query_xs_s_testing.append(pickle.load(open(\"{}/{}/query_x_{}.pkl\".format('testing', state, idx), \"rb\")))\n",
    "        query_ys_s_testing.append(pickle.load(open(\"{}/{}/query_y_{}.pkl\".format('testing', state, idx), \"rb\")))\n",
    "\n",
    "    trained_state_dict = torch.load(model_filename)\n",
    "    melu.load_state_dict(trained_state_dict)\n",
    "\n",
    "    final_loss = []\n",
    "    for i in range(len(supp_xs_s_testing)):\n",
    "        prediction = melu.model(supp_xs_s_testing[i].cuda())\n",
    "        temp_loss = F.mse_loss(prediction, supp_ys_s_testing[i].cuda().view(-1, 1))\n",
    "        final_loss.append(temp_loss.item())\n",
    "\n",
    "    for j in range(len(query_xs_s_testing)):\n",
    "        prediction = melu.model(query_xs_s_testing[j].cuda())\n",
    "        temp_loss = F.mse_loss(prediction, query_ys_s_testing[j].cuda().view(-1, 1))\n",
    "        final_loss.append(temp_loss.item())\n",
    "    testing_losses.append(np.mean(final_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:03<00:00, 20.09it/s]\n",
      "100%|██████████| 67/67 [00:03<00:00, 20.98it/s]\n",
      "100%|██████████| 67/67 [00:03<00:00, 17.14it/s]\n",
      "100%|██████████| 67/67 [00:04<00:00, 14.78it/s]\n",
      "100%|██████████| 4/4 [00:15<00:00,  3.77s/it]\n"
     ]
    }
   ],
   "source": [
    "testing_losses_1 = []\n",
    "for epoch in tqdm(epochs):\n",
    "    model_filename = \"{}/models_{}_{}.pkl\".format(\"models\",state,epoch)\n",
    "    trained_state_dict = torch.load(model_filename)\n",
    "    melu.load_state_dict(trained_state_dict)\n",
    "\n",
    "    final_loss = []\n",
    "    for i in tqdm(range(testing_set_size)):\n",
    "        prediction = melu.forward(supp_xs_s_testing[i].cuda(), supp_ys_s_testing[i].cuda(), query_xs_s_testing[i].cuda(), 5)\n",
    "        temp_loss = F.mse_loss(prediction, query_ys_s_testing[i].cuda().view(-1, 1))\n",
    "        final_loss.append(temp_loss.item())\n",
    "    testing_losses_1.append(np.mean(final_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0591542207038225,\n",
       " 1.0578843508638553,\n",
       " 1.0598142247146636,\n",
       " 1.0597989303407385]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_losses_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 0, 0,  ..., 0, 0, 0],\n",
       "        [5, 0, 0,  ..., 0, 0, 0],\n",
       "        [5, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [5, 0, 0,  ..., 0, 0, 0],\n",
       "        [5, 0, 0,  ..., 0, 0, 0],\n",
       "        [5, 0, 0,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supp_xs_s_testing[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0464284166471283,\n",
       " 1.0464284166471283,\n",
       " 1.0464284166471283,\n",
       " 1.0464284166471283,\n",
       " 1.0691450452849047,\n",
       " 1.020958093120091,\n",
       " 1.0298598736746987,\n",
       " 1.0464284166471283]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9896575985728083,\n",
       " 0.8461494526347598,\n",
       " 0.8154991994032988,\n",
       " 0.7716594467291961]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0691450452849047, 1.020958093120091, 1.0298598736746987, 1.0464284166471283]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_losses[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20, 40, 50, 60]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'user_cold_state'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e59519144975e4f2b0b263ac1715da22f4b122a18ace50518bc05526b1ab231e"
  },
  "kernelspec": {
   "display_name": "Python 3.6.15 ('charanfyp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
