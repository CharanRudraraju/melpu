{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rnautiyal2\\Anaconda3\\envs\\charanfyp\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "from MeLU import MeLU\n",
    "from options import config\n",
    "from model_training import training\n",
    "from data_generation import generate\n",
    "from evidence_candidate import selection\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4348it [00:57, 75.98it/s] \n",
      "484it [00:05, 81.88it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1087it [00:14, 77.50it/s]\n",
      "121it [00:01, 70.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4292it [00:43, 98.64it/s] \n",
      "477it [00:05, 86.64it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1077it [00:10, 98.67it/s] \n",
      "120it [00:01, 99.06it/s]\n"
     ]
    }
   ],
   "source": [
    "master_path= \"./testuserdata\"\n",
    "if not os.path.exists(\"{}/\".format(master_path)):\n",
    "    os.mkdir(\"{}/\".format(master_path))\n",
    "    # preparing dataset. It needs about 22GB of your hard disk space.\n",
    "    generate(master_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [20,40,50,60,80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2393/2393 [00:34<00:00, 69.50it/s]\n",
      "100%|██████████| 20/20 [07:50<00:00, 23.52s/it]\n",
      "100%|██████████| 260/260 [00:03<00:00, 75.67it/s]\n",
      "100%|██████████| 2393/2393 [00:08<00:00, 298.98it/s]\n",
      "100%|██████████| 40/40 [15:33<00:00, 23.33s/it]\n",
      "100%|██████████| 260/260 [00:00<00:00, 348.98it/s]\n",
      "100%|██████████| 2393/2393 [00:07<00:00, 325.98it/s]\n",
      "100%|██████████| 50/50 [19:29<00:00, 23.40s/it]\n",
      "100%|██████████| 260/260 [00:00<00:00, 355.66it/s]\n",
      "100%|██████████| 2393/2393 [00:07<00:00, 314.78it/s]\n",
      "100%|██████████| 60/60 [23:22<00:00, 23.38s/it]\n",
      "100%|██████████| 260/260 [00:00<00:00, 343.46it/s]\n",
      "100%|██████████| 2393/2393 [00:07<00:00, 307.55it/s]\n",
      "100%|██████████| 80/80 [31:10<00:00, 23.38s/it]\n",
      "100%|██████████| 260/260 [00:00<00:00, 354.22it/s]\n"
     ]
    }
   ],
   "source": [
    "state = \"warm_state\"\n",
    "for epoch in epochs:\n",
    "    # training model.\n",
    "    melu = MeLU(config)\n",
    "    state = \"warm_state\"\n",
    "    model_filename = \"{}/models_{}_{}.pkl\".format(master_path,state,epoch)\n",
    "    if not os.path.exists(model_filename):\n",
    "        training_set_size = int(len(os.listdir(\"{}/{}\".format(master_path,state))) / 4)\n",
    "        supp_xs_s = []\n",
    "        supp_ys_s = []\n",
    "        query_xs_s = []\n",
    "        query_ys_s = []\n",
    "        for idx in tqdm(range(training_set_size)):\n",
    "            supp_xs_s.append(pickle.load(open(\"{}/{}/supp_x_{}.pkl\".format(master_path,state, idx), \"rb\")))\n",
    "            supp_ys_s.append(pickle.load(open(\"{}/{}/supp_y_{}.pkl\".format(master_path, state, idx), \"rb\")))\n",
    "            query_xs_s.append(pickle.load(open(\"{}/{}/query_x_{}.pkl\".format(master_path, state, idx), \"rb\")))\n",
    "            query_ys_s.append(pickle.load(open(\"{}/{}/query_y_{}.pkl\".format(master_path, state, idx), \"rb\")))\n",
    "        total_dataset = list(zip(supp_xs_s, supp_ys_s, query_xs_s, query_ys_s))\n",
    "        del(supp_xs_s, supp_ys_s, query_xs_s, query_ys_s)\n",
    "        history = training(melu, total_dataset, batch_size=config['batch_size'], num_epoch=epoch, model_save=True, model_filename=model_filename)\n",
    "        training_losses.append(history[-1])\n",
    "    \n",
    "    testing_set_size = int(len(os.listdir(\"{}/{}\".format('testingtestuser',state))) / 4)\n",
    "    supp_xs_s_testing = []\n",
    "    supp_ys_s_testing = []\n",
    "    query_xs_s_testing = []\n",
    "    query_ys_s_testing = []\n",
    "    for idx in tqdm(range(testing_set_size)):\n",
    "        supp_xs_s_testing.append(pickle.load(open(\"{}/{}/supp_x_{}.pkl\".format('testingtestuser',state, idx), \"rb\")))\n",
    "        supp_ys_s_testing.append(pickle.load(open(\"{}/{}/supp_y_{}.pkl\".format('testingtestuser', state, idx), \"rb\")))\n",
    "        query_xs_s_testing.append(pickle.load(open(\"{}/{}/query_x_{}.pkl\".format('testingtestuser', state, idx), \"rb\")))\n",
    "        query_ys_s_testing.append(pickle.load(open(\"{}/{}/query_y_{}.pkl\".format('testingtestuser', state, idx), \"rb\")))\n",
    "    \n",
    "    trained_state_dict = torch.load(model_filename)\n",
    "    melu.load_state_dict(trained_state_dict)\n",
    "\n",
    "    final_loss = []\n",
    "    for i in range(len(supp_xs_s_testing)):\n",
    "        prediction = melu.model(supp_xs_s_testing[i].cuda())\n",
    "        temp_loss = F.mse_loss(prediction, supp_ys_s_testing[i].cuda().view(-1, 1))\n",
    "        final_loss.append(temp_loss.item())\n",
    "\n",
    "    for j in range(len(query_xs_s_testing)):\n",
    "        prediction = melu.model(query_xs_s_testing[j].cuda())\n",
    "        temp_loss = F.mse_loss(prediction, query_ys_s_testing[j].cuda().view(-1, 1))\n",
    "        final_loss.append(temp_loss.item())\n",
    "    testing_losses.append(np.mean(final_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9072293263153742,\n",
       " 0.8516971904959455,\n",
       " 0.8358650119512673,\n",
       " 0.8121487340271073,\n",
       " 0.7694852420147633]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.035839932784438,\n",
       " 1.0543584047745054,\n",
       " 1.0526656252260391,\n",
       " 1.0656850319069164,\n",
       " 1.106159537543471]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 260/260 [00:08<00:00, 32.09it/s]\n",
      "100%|██████████| 260/260 [00:07<00:00, 32.88it/s]\n",
      "100%|██████████| 260/260 [00:07<00:00, 33.02it/s]\n",
      "100%|██████████| 260/260 [00:07<00:00, 32.68it/s]\n",
      "100%|██████████| 260/260 [00:07<00:00, 32.91it/s]\n",
      "100%|██████████| 5/5 [00:39<00:00,  7.96s/it]\n"
     ]
    }
   ],
   "source": [
    "testing_losses_1 = []\n",
    "for epoch in tqdm(epochs):\n",
    "    model_filename = \"{}/models_{}_{}.pkl\".format(\"testuserdata\",state,epoch)\n",
    "    trained_state_dict = torch.load(model_filename)\n",
    "    melu.load_state_dict(trained_state_dict)\n",
    "\n",
    "    final_loss = []\n",
    "    for i in tqdm(range(testing_set_size)):\n",
    "        prediction = melu.forward(supp_xs_s_testing[i].cuda(), supp_ys_s_testing[i].cuda(), query_xs_s_testing[i].cuda(), 5)\n",
    "        temp_loss = F.mse_loss(prediction, query_ys_s_testing[i].cuda().view(-1, 1))\n",
    "        final_loss.append(temp_loss.item())\n",
    "    testing_losses_1.append(np.mean(final_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.1159570348663972,\n",
       " 1.1162564511769093,\n",
       " 1.116311658718265,\n",
       " 1.1161173694122297,\n",
       " 1.116346623490636]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_losses_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMovieInfo(id):\n",
    "    movie_info = {}\n",
    "    with open(\"./movielens/ml-1m/movies_extrainfos.dat\", encoding=\"utf-8\") as f:\n",
    "        for line in f.readlines():\n",
    "            tmp = line.strip().split(\"::\")\n",
    "            movie_info[tmp[0]] = \"{} ({})\".format(tmp[1], tmp[2])\n",
    "    return movie_info[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'City Hall (1996)'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getMovieInfo('100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e59519144975e4f2b0b263ac1715da22f4b122a18ace50518bc05526b1ab231e"
  },
  "kernelspec": {
   "display_name": "Python 3.6.15 ('charanfyp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
